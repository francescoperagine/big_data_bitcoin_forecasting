{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, cross_val_score, StratifiedKFold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "sys.dont_write_bytecode = True\n",
    "from src.utils.utils import *\n",
    "from src.utils.constants import *\n",
    "from src.visualization.visualize import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>origin_time</th>\n",
       "      <th>next_change</th>\n",
       "      <th>label_positive</th>\n",
       "      <th>label_neutral</th>\n",
       "      <th>label_negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-10-01 00:59:00</td>\n",
       "      <td>-1.084448</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-10-01 01:00:00</td>\n",
       "      <td>-0.161160</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-10-01 01:01:00</td>\n",
       "      <td>0.551711</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-10-01 01:02:00</td>\n",
       "      <td>0.035817</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-10-01 01:03:00</td>\n",
       "      <td>0.185375</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525535</th>\n",
       "      <td>2023-09-30 23:54:00</td>\n",
       "      <td>-0.001528</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525536</th>\n",
       "      <td>2023-09-30 23:55:00</td>\n",
       "      <td>-0.080146</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525537</th>\n",
       "      <td>2023-09-30 23:56:00</td>\n",
       "      <td>0.000903</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525538</th>\n",
       "      <td>2023-09-30 23:57:00</td>\n",
       "      <td>-0.123311</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525539</th>\n",
       "      <td>2023-09-30 23:58:00</td>\n",
       "      <td>-0.001326</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>524101 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               origin_time  next_change  label_positive  label_neutral  \\\n",
       "0      2022-10-01 00:59:00    -1.084448           False          False   \n",
       "1      2022-10-01 01:00:00    -0.161160           False           True   \n",
       "2      2022-10-01 01:01:00     0.551711           False           True   \n",
       "3      2022-10-01 01:02:00     0.035817           False           True   \n",
       "4      2022-10-01 01:03:00     0.185375           False           True   \n",
       "...                    ...          ...             ...            ...   \n",
       "525535 2023-09-30 23:54:00    -0.001528           False           True   \n",
       "525536 2023-09-30 23:55:00    -0.080146           False           True   \n",
       "525537 2023-09-30 23:56:00     0.000903           False           True   \n",
       "525538 2023-09-30 23:57:00    -0.123311           False           True   \n",
       "525539 2023-09-30 23:58:00    -0.001326           False           True   \n",
       "\n",
       "        label_negative  \n",
       "0                 True  \n",
       "1                False  \n",
       "2                False  \n",
       "3                False  \n",
       "4                False  \n",
       "...                ...  \n",
       "525535           False  \n",
       "525536           False  \n",
       "525537           False  \n",
       "525538           False  \n",
       "525539           False  \n",
       "\n",
       "[524101 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth = pd.read_pickle(GROUND_TRUTH_PROCESSED_PATH)\n",
    "ground_truth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "\n",
    "for exchange in EXCHANGES:\n",
    "    exchange_candles = pd.read_parquet(os.path.join(INTERIM_DATA_PATH, f'{exchange}_{CANDLES}_pca_data.parquet'))\n",
    "    exchange_orderbook = pd.read_parquet(os.path.join(INTERIM_DATA_PATH, f'{exchange}_{ORDERBOOKS}_pca_data.parquet'))\n",
    "\n",
    "    data[exchange] = ground_truth.merge(exchange_candles, on='origin_time', how='inner').merge(exchange_orderbook, on='origin_time', how='inner')\n",
    "    display(data[exchange].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for exchange in EXCHANGES:\n",
    "    df = data[(CANDLES, exchange)]\n",
    "\n",
    "    cols_to_drop = ['origin_time', 'label']\n",
    "    merged_df = pd.merge(ground_truth[cols_to_drop], df, on='origin_time', how='inner')\n",
    "    X = merged_df.drop(cols_to_drop, axis=1)\n",
    "    y = merged_df['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(param_distributions, pipeline, X, y):\n",
    "    \n",
    "    inner_cv = StratifiedKFold(n_splits=INNER_CV_FOLDS, shuffle=True, random_state=RANDOM_STATE)\n",
    "    \n",
    "    randomized_search = RandomizedSearchCV(\n",
    "        estimator=pipeline,\n",
    "        param_distributions=param_distributions,\n",
    "        cv=inner_cv,\n",
    "        scoring='accuracy',\n",
    "        n_jobs=-1,\n",
    "        random_state=RANDOM_STATE,\n",
    "        error_score='raise',\n",
    "        return_train_score=True\n",
    "    )\n",
    "    \n",
    "    randomized_search.fit(X, y)\n",
    "\n",
    "    cv_results = pd.DataFrame(randomized_search.cv_results_)\n",
    "    best_params = randomized_search.best_params_\n",
    "    best_score = randomized_search.best_score_\n",
    "    best_clf = randomized_search.best_estimator_\n",
    "\n",
    "    return cv_results, best_params, best_score, best_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the SMOTE and undersampler\n",
    "\n",
    "# smote = SMOTE(random_state=RANDOM_STATE)\n",
    "# undersample = RandomUnderSampler(random_state=RANDOM_STATE)\n",
    "# smote_enn = SMOTEENN(smote=smote, random_state=RANDOM_STATE)\n",
    "\n",
    "# # Create a pipeline\n",
    "# pipeline = Pipeline(steps=[('smote_enn', smote_enn), ('classifier', RandomForestClassifier(random_state=RANDOM_STATE, class_weight='balanced_subsample'))])\n",
    "\n",
    "# # Define the hyperparameter search space\n",
    "# param_distributions = {\n",
    "#     'classifier__criterion': ['gini', 'entropy'],\n",
    "#     'classifier__n_estimators': [200, 300, 400, 500],\n",
    "#     'classifier__ccp_alpha': [0, 0.001, 0.005, 0.01, 0.02],\n",
    "#     'classifier__min_samples_split': [10, 20, 30],\n",
    "#     'classifier__min_samples_leaf': [5, 10, 15],\n",
    "#     'classifier__max_depth': [5, 10, 20, 30],\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distributions = {\n",
    "    'depth': [5, 10, 20, 30],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'n_estimators': [200, 300, 400, 500],\n",
    "    'ccp_alpha': [0, 0.001, 0.005, 0.01, 0.02],\n",
    "    'min_samples_split': [10, 20, 30],\n",
    "    'min_samples_leaf': [5, 10, 15],\n",
    "    'max_depth': [5, 10, 20, 30],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "model_data = {}\n",
    "\n",
    "for (data_type, exchange), df in data.items():\n",
    "\n",
    "        cols_to_drop = ['origin_time', 'label']\n",
    "        merged_df = pd.merge(ground_truth[cols_to_drop], df, on='origin_time', how='inner')\n",
    "        X = merged_df.drop(cols_to_drop, axis=1)\n",
    "        y = merged_df['label']\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y)\n",
    "        cv_results, best_params, best_score, best_clf = process_dataset(param_distributions, pipeline, X_train, y_train)\n",
    "\n",
    "        y_pred = best_clf.predict(X_test)\n",
    "        evaluation = get_evaluation(y_test, y_pred)\n",
    "\n",
    "        results[(data_type, exchange)] = {\n",
    "                'cv_results': cv_results,\n",
    "                'best_params': best_params,\n",
    "                'best_score': best_score,\n",
    "                'accuracy': evaluation['accuracy'],\n",
    "                'classification_report': evaluation['classification_report'],\n",
    "                'confusion_matrix': evaluation['confusion_matrix']\n",
    "        }\n",
    "        model_data[(data_type, exchange)] = {\n",
    "                'X_train': X_train,\n",
    "                'y_train': y_train,\n",
    "                'X_test': X_test,\n",
    "                'y_test': y_test,\n",
    "                'y_pred': y_pred,\n",
    "        }\n",
    "        pd.DataFrame.to_pickle(results[(exchange, data_type)], os.path.join(PROCESSED_DATA_PATH, f\"{exchange}_{data_type}_random_forest_results.pkl\"))\n",
    "        pd.DataFrame.to_pickle(model_data[(exchange, data_type)], os.path.join(PROCESSED_DATA_PATH, f\"{exchange}_{data_type}_random_forest_model_data.pkl\"))\n",
    "        pd.DataFrame.to_pickle(best_clf, os.path.join(MODELS_DATA_PATH, f'{exchange}_{data_type}_random_forest_best_clf.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for (data_type, exchange), df in results.items():\n",
    "#     path = os.path.join(MODELS_DATA_PATH, f'{data_type}_{exchange}_random_forest_best_clf.pkl')\n",
    "\n",
    "#     best_clf = pd.read_pickle(os.path.join(MODELS_DATA_PATH, f'{data_type}_{exchange}_random_forest_best_clf.pkl'))\n",
    "#     plot_learning_curve(\n",
    "#         exchange,\n",
    "#         data_type,\n",
    "#         'random_forest',\n",
    "#         best_clf,\n",
    "#         model_data[(data_type, exchange)]['X_train'],\n",
    "#         model_data[(data_type, exchange)]['y_train'],\n",
    "#         train_sizes=np.linspace(0.1, 1.0, 3),\n",
    "#         cv=INNER_CV_FOLDS\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for (data_type, exchange), df in results.items():\n",
    "#     plot_confusion_matrix(\n",
    "#         exchange,\n",
    "#         data_type,\n",
    "#         'random_forest',\n",
    "#         df['confusion_matrix'],\n",
    "#         labels=['positive', 'neutral', 'negative']\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for (data_type, exchange), df in results.items():\n",
    "#         # Analyzing cv_results_ to check for overfitting\n",
    "#     cv_results = df['cv_results']\n",
    "#     cv_results['score_diff'] = cv_results['mean_train_score'] - cv_results['mean_test_score']\n",
    "#     overfitting_threshold = 0.1  # Define a threshold for overfitting\n",
    "#     overfitting = cv_results[cv_results['score_diff'] > overfitting_threshold]\n",
    "\n",
    "#     if not overfitting.empty:\n",
    "#             print(\"Possible overfitting detected in the following parameter combinations:\")\n",
    "#             print(overfitting[['params', 'mean_train_score', 'mean_test_score', 'score_diff']])\n",
    "#     else:\n",
    "#             print(\"No significant overfitting detected.\")\n",
    "#     display(f'{exchange} {data_type} Random Forest:\\nbest score {df[\"best_score\"]}')\n",
    "#     display(pd.DataFrame.from_dict(df['best_params'], orient='index').T)\n",
    "#     display(df['confusion_matrix'])\n",
    "#     display(df['classification_report'])\n",
    "#     display(df['cv_results'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
