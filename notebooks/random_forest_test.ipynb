{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, cross_val_score, KFold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# import dask\n",
    "# from dask.distributed import Client\n",
    "# from dask.dataframe import from_pandas\n",
    "# import socket\n",
    "# from dotenv import load_dotenv\n",
    "\n",
    "# src_path = os.path.abspath(os.path.join('..'))\n",
    "# if src_path not in sys.path:\n",
    "#     sys.path.append(src_path)\n",
    "\n",
    "sys.dont_write_bytecode = True\n",
    "from src.utils.utils import *\n",
    "from src.utils.constants import *\n",
    "from src.visualization.visualize import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_dotenv()\n",
    "# scheduler_address = os.getenv(\"DISTRIBUTED_MAIN_IP\")\n",
    "# client = Client(\"192.168.1.58:8786\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = pd.read_parquet(GROUND_TRUTH_PATH)\n",
    "ground_truth = ground_truth[['origin_time', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "\n",
    "for exchange in EXCHANGES:\n",
    "    data[(CANDLES, exchange)] = pd.read_parquet(os.path.join(INTERIM_DATA_PATH, f'{exchange}_{CANDLES}_pca_data.parquet'))\n",
    "    data[(ORDERBOOKS, exchange)] = pd.read_parquet(os.path.join(INTERIM_DATA_PATH, f'{exchange}_{ORDERBOOKS}_pca_data.parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_df = {}\n",
    "# cols_to_drop = ['origin_time', 'label']\n",
    "\n",
    "# for (data_type, exchange), df in data.items():     \n",
    "#     merged_df[(data_type, exchange)] = {}\n",
    "#     merged_df[(data_type, exchange)]['full'] = pd.merge(ground_truth[cols_to_drop], df, on='origin_time', how='inner')\n",
    "#     merged_df[(data_type, exchange)]['X'] = merged_df[(data_type, exchange)]['full'].drop(cols_to_drop, axis=1)\n",
    "#     merged_df[(data_type, exchange)]['y'] = merged_df[(data_type, exchange)]['full']['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def process_dataset(param_distributions, df):\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(df['X'], df['y'], test_size=TEST_SIZE, random_state=RANDOM_STATE)\n",
    "\n",
    "#     # Nested Cross-Validation: Uses an outer loop for model evaluation and an inner loop for hyperparameter tuning.\n",
    "#     outer_cv = KFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "#     inner_cv = KFold(n_splits=3, shuffle=True, random_state=RANDOM_STATE)\n",
    "    \n",
    "#     clf = RandomForestClassifier(random_state=RANDOM_STATE)\n",
    "\n",
    "#     # Initialize the RandomizedSearchCV object\n",
    "#     randomized_search = RandomizedSearchCV(estimator=clf, param_distributions=param_distributions, n_iter=50, cv=CV_FOLDS, scoring='accuracy', n_jobs=-1, random_state=RANDOM_STATE)\n",
    "\n",
    "#     # Perform nested cross-validation\n",
    "#     nested_scores = cross_val_score(randomized_search, df['X'], df['y'], cv=outer_cv, scoring='accuracy')\n",
    "\n",
    "#     # Fit the random search to the data\n",
    "#     randomized_search.fit(X_train, y_train)\n",
    "\n",
    "#     # Best parameters and score\n",
    "#     best_params = randomized_search.best_params_\n",
    "#     best_score = randomized_search.best_score_\n",
    "#     best_clf = randomized_search.best_estimator_\n",
    "\n",
    "#     # Predict on the test set\n",
    "#     y_pred = best_clf.predict(X_test)\n",
    "\n",
    "#     # Evaluate the model\n",
    "#     evaluation = get_evaluation(y_test, y_pred)\n",
    "\n",
    "#     train_scores = []\n",
    "#     test_scores = []\n",
    "#     n_estimators_range = param_distributions['n_estimators']\n",
    "\n",
    "#     for n_estimators in n_estimators_range:\n",
    "#         model = RandomForestClassifier(\n",
    "#             criterion=best_params['criterion'],\n",
    "#             random_state=RANDOM_STATE, \n",
    "#             n_estimators=n_estimators,\n",
    "#             max_depth=best_params['max_depth'],\n",
    "#             min_samples_split=best_params['min_samples_split'], \n",
    "#             min_samples_leaf=best_params['min_samples_leaf']\n",
    "#         )\n",
    "        \n",
    "#         # Cross-validation on the training data\n",
    "#         train_cv_results = cross_val_score(model, df['X_train'], df['y_train'], cv=inner_cv, scoring='accuracy')\n",
    "#         train_scores.append(train_cv_results.mean())\n",
    "        \n",
    "#         # Evaluate on the test set\n",
    "#         model.fit(df['X_train'], df['y_train'])\n",
    "#         test_score = model.score(df['X_test'], df['y_test'])\n",
    "#         test_scores.append(test_score)\n",
    "\n",
    "#     return {\n",
    "#         'best_params': best_params,\n",
    "#         'best_score': best_score,\n",
    "#         'nested_scores': nested_scores,\n",
    "#         'evaluation': evaluation,\n",
    "#         'train_scores': train_scores,\n",
    "#         'test_scores': test_scores,\n",
    "#         'n_estimators_range': n_estimators_range\n",
    "#     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(param_distributions, X, y):\n",
    "\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE)\n",
    "\n",
    "    smote = SMOTE(random_state=RANDOM_STATE)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    inner_cv = KFold(n_splits=CV_FOLDS, shuffle=True, random_state=RANDOM_STATE)\n",
    "    \n",
    "    clf = RandomForestClassifier(random_state=RANDOM_STATE, class_weight='balanced_subsample', verbose=3)\n",
    "\n",
    "    randomized_search = RandomizedSearchCV(\n",
    "        estimator=clf,\n",
    "        param_distributions=param_distributions,\n",
    "        cv=inner_cv,\n",
    "        scoring='accuracy',\n",
    "        n_jobs=-1,\n",
    "        random_state=RANDOM_STATE,\n",
    "        verbose=3,\n",
    "        error_score='raise',\n",
    "        return_train_score=True\n",
    "    )\n",
    "    \n",
    "    randomized_search.fit(X_resampled, y_resampled)\n",
    "\n",
    "    best_params = randomized_search.best_params_\n",
    "    best_score = randomized_search.best_score_\n",
    "    best_clf = randomized_search.best_estimator_\n",
    "\n",
    "    y_pred = best_clf.predict(X_test)\n",
    "    accuracy, classification_report, confusion_matrix = get_evaluation(y_test, y_pred)\n",
    "\n",
    "    plot_confusion_matrix(y_test, y_pred, labels=['positive', 'neutral', 'negative'])\n",
    "    plot_learning_curve(best_clf, X_resampled, y_resampled)\n",
    "\n",
    "    return {\n",
    "        'best_params': best_params,\n",
    "        'best_score': best_score,\n",
    "        'accuracy': accuracy,\n",
    "        'classification_report': classification_report,\n",
    "        'confusion_matrix': confusion_matrix\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distributions = {\n",
    "    'criterion': 'gini',\n",
    "    'n_estimators': [50, 100, 200, 300, 500],\n",
    "    'ccp_alpha': [0, 0.001, 0.005, 0.010],\n",
    "    'min_samples_split': [2, 10, 20, 30, 50],\n",
    "    'min_samples_leaf': [1, 5, 10, 20, 30]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Repository\\big_data_bitcoin_forecasting\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "f:\\Repository\\big_data_bitcoin_forecasting\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "f:\\Repository\\big_data_bitcoin_forecasting\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Repository\\big_data_bitcoin_forecasting\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "f:\\Repository\\big_data_bitcoin_forecasting\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "f:\\Repository\\big_data_bitcoin_forecasting\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "for (data_type, exchange), df in data.items():\n",
    "\n",
    "    cols_to_drop = ['origin_time', 'label']\n",
    "    merged_df = pd.merge(ground_truth[cols_to_drop], df, on='origin_time', how='inner')\n",
    "    X = merged_df.drop(cols_to_drop, axis=1)\n",
    "    y = merged_df['label']\n",
    "    results[(data_type, exchange)] = process_dataset(param_distributions, X, y)\n",
    "\n",
    "    pd.DataFrame.to_pickle(results[(data_type, exchange)], os.path.join(PROCESSED_DATA_PATH, f\"{exchange}_{data_type}_random_forest_result.pkl\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 50, 'min_samples_split': 20, 'min_samples_leaf': 30, 'criterion': 'gini', 'ccp_alpha': 0}\n",
      "0.6994329652399247\n",
      "[0.69926335 0.69905948 0.69958954 0.70004757 0.69868841]\n",
      "0.6978092374827162\n",
      "              precision    recall  f1-score        support\n",
      "positive       0.392096  0.087099  0.142536   24719.000000\n",
      "neutral        0.721360  0.973015  0.828499  108395.000000\n",
      "negative       0.401778  0.097564  0.157003   24548.000000\n",
      "accuracy       0.697809  0.697809  0.697809       0.697809\n",
      "macro avg      0.505078  0.385893  0.376012  157662.000000\n",
      "weighted avg   0.619977  0.697809  0.616398  157662.000000\n",
      "               pred:positive  pred:neutral  pred:negative\n",
      "true:positive           2153         20479           2087\n",
      "true:neutral            1446        105470           1479\n",
      "true:negative           1892         20261           2395\n",
      "{'n_estimators': 50, 'min_samples_split': 50, 'min_samples_leaf': 20, 'criterion': 'gini', 'ccp_alpha': 0.01}\n",
      "0.6934123855456638\n",
      "[0.69266028 0.69565153 0.69364248 0.69176737 0.69329563]\n",
      "0.6923557722357647\n",
      "              precision    recall  f1-score        support\n",
      "positive       0.000000  0.000000  0.000000   22109.000000\n",
      "neutral        0.692356  1.000000  0.818215   99693.000000\n",
      "negative       0.000000  0.000000  0.000000   22189.000000\n",
      "accuracy       0.692356  0.692356  0.692356       0.692356\n",
      "macro avg      0.230785  0.333333  0.272738  143991.000000\n",
      "weighted avg   0.479357  0.692356  0.566496  143991.000000\n",
      "               pred:positive  pred:neutral  pred:negative\n",
      "true:positive              0         22109              0\n",
      "true:neutral               0         99693              0\n",
      "true:negative              0         22189              0\n",
      "{'n_estimators': 50, 'min_samples_split': 20, 'min_samples_leaf': 30, 'criterion': 'gini', 'ccp_alpha': 0}\n",
      "0.7059018303142459\n",
      "[0.70512188 0.70653093 0.70626673 0.70700132 0.70432409]\n",
      "0.7044212291329328\n",
      "              precision    recall  f1-score        support\n",
      "positive       0.384229  0.054335  0.095206   18294.000000\n",
      "neutral        0.719980  0.982197  0.830891   84931.000000\n",
      "negative       0.401183  0.069910  0.119071   18438.000000\n",
      "accuracy       0.704421  0.704421  0.704421       0.704421\n",
      "macro avg      0.501797  0.368814  0.348389  121663.000000\n",
      "weighted avg   0.621180  0.704421  0.612393  121663.000000\n",
      "               pred:positive  pred:neutral  pred:negative\n",
      "true:positive            994         16168           1132\n",
      "true:neutral             720         83419            792\n",
      "true:negative            873         16276           1289\n",
      "{'n_estimators': 50, 'min_samples_split': 50, 'min_samples_leaf': 20, 'criterion': 'gini', 'ccp_alpha': 0.01}\n",
      "0.6923102147869171\n",
      "[0.69029925 0.69151662 0.69313371 0.6909114  0.69554473]\n",
      "0.6902896486229819\n",
      "              precision    recall  f1-score       support\n",
      "positive       0.000000  0.000000  0.000000   18133.00000\n",
      "neutral        0.690290  1.000000  0.816771   81410.00000\n",
      "negative       0.000000  0.000000  0.000000   18393.00000\n",
      "accuracy       0.690290  0.690290  0.690290       0.69029\n",
      "macro avg      0.230097  0.333333  0.272257  117936.00000\n",
      "weighted avg   0.476500  0.690290  0.563808  117936.00000\n",
      "               pred:positive  pred:neutral  pred:negative\n",
      "true:positive              0         18133              0\n",
      "true:neutral               0         81410              0\n",
      "true:negative              0         18393              0\n",
      "{'n_estimators': 50, 'min_samples_split': 20, 'min_samples_leaf': 30, 'criterion': 'gini', 'ccp_alpha': 0}\n",
      "0.7057949002035498\n",
      "[0.706735   0.70802071 0.7050214  0.70562023 0.70357715]\n",
      "0.707132641822695\n",
      "              precision    recall  f1-score        support\n",
      "positive       0.391971  0.069902  0.118646   18297.000000\n",
      "neutral        0.725749  0.978991  0.833560   85012.000000\n",
      "negative       0.410250  0.083292  0.138471   18357.000000\n",
      "accuracy       0.707133  0.707133  0.707133       0.707133\n",
      "macro avg      0.509323  0.377395  0.363559  121666.000000\n",
      "weighted avg   0.627950  0.707133  0.621171  121666.000000\n",
      "               pred:positive  pred:neutral  pred:negative\n",
      "true:positive           1279         15751           1267\n",
      "true:neutral             855         83226            931\n",
      "true:negative           1129         15699           1529\n",
      "{'n_estimators': 100, 'min_samples_split': 20, 'min_samples_leaf': 10, 'criterion': 'gini', 'ccp_alpha': 0}\n",
      "0.6923356520878607\n",
      "[0.69033559 0.6916438  0.69318822 0.69085689 0.69558107]\n",
      "0.6903066069732736\n",
      "              precision    recall  f1-score        support\n",
      "positive       0.333333  0.000165  0.000331   18133.000000\n",
      "neutral        0.690382  0.999914  0.816807   81410.000000\n",
      "negative       0.352941  0.000326  0.000652   18393.000000\n",
      "accuracy       0.690307  0.690307  0.690307       0.690307\n",
      "macro avg      0.458886  0.333469  0.272597  117936.000000\n",
      "weighted avg   0.582859  0.690307  0.563986  117936.000000\n",
      "               pred:positive  pred:neutral  pred:negative\n",
      "true:positive              3         18125              5\n",
      "true:neutral               1         81403              6\n",
      "true:negative              5         18382              6\n"
     ]
    }
   ],
   "source": [
    "for (data_type, exchange), df in data.items():\n",
    "    print(results[(data_type, exchange)]['best_params'])\n",
    "    print(results[(data_type, exchange)]['best_score'])\n",
    "    print(results[(data_type, exchange)]['nested_scores'])\n",
    "    print(results[(data_type, exchange)]['evaluation']['accuracy'])\n",
    "    print(results[(data_type, exchange)]['evaluation']['classification_report'])\n",
    "    print(results[(data_type, exchange)]['evaluation']['confusion_matrix'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = {}\n",
    "# for (data_type, exchange), df in merged_df.items():\n",
    "#     future = client.submit(process_dataset(data_type, exchange, param_distributions, merged_df[(CANDLES, BINANCE)]))\n",
    "#     results[(data_type, exchange)] = future.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for (data_type, exchange), result in zip(merged_df.keys(), results):\n",
    "#     print(f\"Results for {exchange} {data_type}:\")\n",
    "#     print(f\"Best parameters for {exchange} {data_type}: {result['best_params']}\")\n",
    "#     print(f'Nested CV Accuracy: {result[\"nested_scores\"].mean():.2f}')\n",
    "#     print(f'Test Set Accuracy: {result[\"evaluation\"][\"accuracy\"]:.2f}')\n",
    "#     print(f'Classification Report:')\n",
    "#     display(result['evaluation']['classification_report'])\n",
    "#     print(f'Confusion Matrix:')\n",
    "#     display(result['evaluation']['confusion_matrix'])\n",
    "\n",
    "#     plot_tree_learning_curves(exchange, data_type, result['depths'], result['train_scores'], result['test_scores'], 'random_forest')\n",
    "\n",
    "#     pd.DataFrame.to_pickle(result, os.path.join(PROCESSED_DATA_PATH, f'{exchange}_{data_type}_random_forest_results.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for (data_type, exchange), df in merged_df.items():\n",
    "#     result = process_dataset(data_type, exchange, param_distributions, df)\n",
    "#     print(f\"Results for {exchange} {data_type}:\")\n",
    "#     print(f\"Best parameters: {result['best_params']}\")\n",
    "#     print(f'Nested CV Accuracy: {result[\"nested_scores\"].mean():.2f}')\n",
    "#     print(f'Accuracy: {result[\"evaluation\"][\"accuracy\"]:.2f}')\n",
    "#     print(f'Classification Report:')\n",
    "#     display(result['evaluation']['classification_report'])\n",
    "#     print(f'Confusion Matrix:')\n",
    "#     display(result['evaluation']['confusion_matrix'])\n",
    "#     plot_tree_learning_curves(exchange, data_type, result['depths'], result['train_scores'], result['test_scores'], 'random_forest')\n",
    "#     pd.DataFrame.to_pickle(result, os.path.join(PROCESSED_DATA_PATH, f'{exchange}_{data_type}_random_forest_results.pkl'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
