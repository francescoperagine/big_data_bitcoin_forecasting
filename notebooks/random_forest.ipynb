{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.dont_write_bytecode = True\n",
    "import os\n",
    "from itertools import product\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from src.models.train_model import BTCForecasting\n",
    "\n",
    "import pickle\n",
    "import gc\n",
    "\n",
    "from src.utils.utils import *\n",
    "from src.utils.constants import *\n",
    "from src.visualization.visualize import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifiers\n",
    "\n",
    "classifiers = {\n",
    "    'RFC_balanced_subsample': RandomForestClassifier(random_state=RANDOM_STATE, class_weight='balanced_subsample', n_jobs=-1),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training params\n",
    "\n",
    "view_params = {\n",
    "    'candles': {\n",
    "        'use_smoteenn': False,\n",
    "        'feature_selection': 'sfm',\n",
    "        'factor': 2,\n",
    "        'aggresive_elimination': False,\n",
    "        'n_splits': 3,\n",
    "        'classifier__max_depth': range(5, 20),\n",
    "        'classifier__min_samples_leaf': range(1, 2, 1),\n",
    "        'classifier__min_samples_split': range(2, 10, 2),\n",
    "        'classifier__max_leaf_nodes': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "    },\n",
    "    'orderbook': {\n",
    "        'use_smoteenn': False,\n",
    "        'feature_selection': 'sfm',\n",
    "        'factor': 2,\n",
    "        'aggresive_elimination': False,\n",
    "        'n_splits': 3,\n",
    "        'classifier__max_depth': range(5, 20),\n",
    "        'classifier__min_samples_leaf': range(1, 2, 1),\n",
    "        'classifier__min_samples_split': range(2, 20, 2),\n",
    "        'classifier__max_leaf_nodes': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "    },\n",
    "    'unified': {\n",
    "        'use_smoteenn': False,\n",
    "        'feature_selection': 'sfm',\n",
    "        'factor': 2,\n",
    "        'aggresive_elimination': False,\n",
    "        'n_splits': 3,\n",
    "        'classifier__max_depth': range(5, 20),\n",
    "        'classifier__min_samples_leaf': range(1, 2, 1),\n",
    "        'classifier__min_samples_split': range(2, 20, 2),\n",
    "        'classifier__max_leaf_nodes': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "\n",
    "data = {\n",
    "    (exchange, data_type): pd.read_parquet(\n",
    "        os.path.join(INTERIM_DATA_PATH, f'{exchange}_{data_type}_data.parquet')\n",
    "    )\n",
    "    for exchange, data_type in product(EXCHANGES, DATA_TYPES)\n",
    "}\n",
    "data[(ALL, UNIFIED)] = pd.read_parquet(os.path.join(INTERIM_DATA_PATH, f'{ALL}_{UNIFIED}_data.parquet'))\n",
    "\n",
    "ground_truth = pd.read_parquet(os.path.join(INTERIM_DATA_PATH, 'ground_truth_data.parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "\n",
    "model_params = {}\n",
    "\n",
    "for (name, classifier) in classifiers.items():\n",
    "    for (exchange, data_type), df in data.items():\n",
    "        \n",
    "        params = view_params[data_type]\n",
    "\n",
    "        use_smoteenn = params['use_smoteenn']\n",
    "        factor = params['factor']\n",
    "        aggressive_elimination = params['aggresive_elimination']\n",
    "        n_splits = params['n_splits']\n",
    "        \n",
    "        print(f\"\\nStarting training {name} model for {exchange} - {data_type}\")\n",
    "\n",
    "        btcf = BTCForecasting(\n",
    "            df, \n",
    "            ground_truth,\n",
    "            n_splits=n_splits,\n",
    "            smoteenn=use_smoteenn,\n",
    "            pca_variance_threshold=PCA_VARIANCE_THRESHOLD,\n",
    "            feature_selection=params['feature_selection'],\n",
    "        )\n",
    "\n",
    "        model_params = {k: v for k, v in params.items() if k.startswith('classifier__')}\n",
    "\n",
    "        btcf.train(classifier, model_params, factor=factor, aggressive_elimination=aggressive_elimination, verbose=3)\n",
    "\n",
    "        save_model(btcf, name, exchange, data_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "\n",
    "for classifier_name, _ in classifiers.items():\n",
    "        for exchange, data_type in product(EXCHANGES, DATA_TYPES):\n",
    "                model_path = os.path.join(MODELS_DATA_PATH, f\"{classifier_name}_{exchange}_{data_type}.pkl\")\n",
    "                \n",
    "                if not os.path.exists(model_path):\n",
    "                    continue\n",
    "\n",
    "                with open(model_path, \"rb\") as model_file:\n",
    "                    btcf = pickle.load(model_file)\n",
    "\n",
    "                btcf.evaluate()\n",
    "\n",
    "                save_model(btcf, classifier_name, exchange, data_type)\n",
    "                \n",
    "                print(f\"\\nBest {classifier_name} model for {exchange} - {data_type}\")\n",
    "                \n",
    "                # Plots\n",
    "                filename_prefix = f\"{classifier_name}_{exchange}_{data_type}\"\n",
    "                val_curve_param = 'classifier__max_depth'\n",
    "\n",
    "                btcf.plot_learn_cm_feat(f\"{filename_prefix}_learn_val_feat.png\")\n",
    "                btcf.plot_bias_variance_tradeoff(f\"{filename_prefix}_bias_variance_tradeoff.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results\n",
    "\n",
    "eval_results = []\n",
    "t_test_data = []\n",
    "comparison_data = []\n",
    "t_test_metrics = ['mean_test_score', 'mean_train_score', 'std_test_score', 'std_train_score']\n",
    "\n",
    "for classifier_name, _ in classifiers.items():\n",
    "        for exchange, data_type in product(EXCHANGES, DATA_TYPES):\n",
    "                \n",
    "                model_path = os.path.join(MODELS_DATA_PATH, f\"{classifier_name}_{exchange}_{data_type}.pkl\")\n",
    "                if not os.path.exists(model_path):\n",
    "                    continue\n",
    "\n",
    "                with open(model_path, \"rb\") as model_file:\n",
    "                    btcf = pickle.load(model_file)\n",
    "\n",
    "                eval_metrics = [x for x in btcf.results.keys() if x not in ['best_params', 'conf_matrix', 'cv_results', 'classification_report', 'feature_selection']]\n",
    "                metrics_dict = {metric: btcf.results[metric] for metric in eval_metrics}\n",
    "                eval_record = {\n",
    "                    'classifier': classifier_name,\n",
    "                    'exchange': exchange,\n",
    "                    'data_type': data_type\n",
    "                }\n",
    "                \n",
    "                eval_record.update(btcf.results['best_params'])  \n",
    "                eval_record.update(metrics_dict)\n",
    "                eval_results.append(eval_record)\n",
    "\n",
    "                t_record = { metric: btcf.results['cv_results'][metric] for metric in t_test_metrics }\n",
    "                t_record.update({'exchange': exchange, 'data_type': data_type, 'classifier': classifier_name })\n",
    "                t_test_data.append(t_record)\n",
    "\n",
    "                comparison_record = {**eval_record, **t_record}\n",
    "                comparison_data.append(comparison_record)\n",
    "\n",
    "results_df = pd.DataFrame(eval_results)\n",
    "results_df.to_csv(os.path.join(REPORTS_PATH, 'results.csv'), index=False)\n",
    "display(results_df)\n",
    "\n",
    "data_types = results_df['data_type'].unique()\n",
    "all_comparisons = pd.concat([compute_comparison(pd.DataFrame(comparison_data), data_type) for data_type in data_types], ignore_index=True)\n",
    "display(all_comparisons)\n",
    "\n",
    "ttest_results = pd.concat([perform_ttest(pd.DataFrame(t_test_data), metric) for metric in t_test_metrics], ignore_index=True)\n",
    "display(ttest_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
